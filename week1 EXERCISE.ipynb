{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "   raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"✅ API key loaded successfully!\")\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98e5940-024e-4121-ae40-1b2f80893f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents and explain like 5 year old \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Please give a detailed explanation to the following question: {question}.\n",
    "Be less verbose.\n",
    "Provide a clear and concise explanation without unnecessary elaboration.\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hello, I am your personal technical tutor. Enter your question:  Please explain what this code does and why: yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n"
     ]
    }
   ],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "while True:\n",
    "    question = input(\"Hello, I am your personal technical tutor. Enter your question: \").strip()\n",
    "    if question:\n",
    "        break  # Proceed only if a valid question is entered\n",
    "    print(\"Question cannot be empty. Please enter a question.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! \n",
      "\n",
      "### Summary\n",
      "\n",
      "The code `yield from {book.get(\"author\") for book in books if book.get(\"author\")}` does the following:\n",
      "\n",
      "1. **Loop through `books`:** It goes through each book in a list called `books`.\n",
      "2. **Get the author:** For each book, it tries to find the author using `book.get(\"author\")`.\n",
      "3. **Check if there's an author:** It only keeps the author if it exists (not empty).\n",
      "4. **Create a set of authors:** It makes a set of all the authors found (a set means no duplicates).\n",
      "5. **Yield authors:** It uses `yield from` to return each author one by one.\n",
      "\n",
      "### Explanation for a 5-Year-Old\n",
      "\n",
      "Think of it like this: Imagine you have a box of toys, and each toy has a sticker with the name of its owner. This code is like saying, “Show me the names of the owners for the toys that have stickers on them, but only show each name once!”\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Python generator expression, specifically using the `yield from` syntax. Let's break it down:\n",
      "\n",
      "**What it does:**\n",
      "\n",
      "The code yields (returns) an iterator that generates a sequence of authors from a list of dictionaries (`books`). Each dictionary represents a book, and each book has an \"author\" key.\n",
      "\n",
      "The generated authors are only included if the corresponding book has an \"author\" value (i.e., not `None` or an empty string).\n",
      "\n",
      "**Why it's written this way:**\n",
      "\n",
      "This code is using a generator expression to create an iterator that yields authors from the list of books. Here's why:\n",
      "\n",
      "* **Efficiency:** By using a generator expression, you don't need to load all the authors into memory at once. The iterator will lazily generate authors on demand.\n",
      "* **Flexibility:** You can use this code in various contexts where you need to process authors, such as:\n",
      "\t+ Filtering or sorting authors\n",
      "\t+ Creating a set or a list of unique authors\n",
      "\t+ Iterating over authors for further processing\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "Here's a step-by-step explanation:\n",
      "\n",
      "1. `for book in books`: Iterate over each book in the `books` list.\n",
      "2. `if book.get(\"author\")`: Check if the current book has an \"author\" value (i.e., not `None` or an empty string). If it does, proceed to the next step.\n",
      "3. `{book.get(\"author\") for ...}`: Use a set comprehension to create a set of unique authors from the books that have an author.\n",
      "4. `yield from`: Yield (return) this set iterator as the result.\n",
      "\n",
      "By using `yield from`, you're essentially saying, \"Hey, I've got a generator expression here; just let it run and yield the results.\" This allows the caller to iterate over the authors without worrying about the implementation details.\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "import ollama\n",
    "\n",
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3:8b',  # ✅ model name must exactly match what you've pulled\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': question }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749d60f-e50c-481d-b236-ce7ed0b39260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
